#!/usr/bin/env python3

#
# Copyright (c) Mark Johnston <markj@FreeBSD.org>
#
# SPDX-License-Identifier: BSD-2-Clause
#

import argparse
import functools
import inspect
import json
import os
import re
import shutil
import sys
import textwrap
from abc import ABC, ABCMeta, abstractmethod
from enum import Enum
from pathlib import Path
from types import SimpleNamespace
from typing import Any, Dict, List, Optional, Set, Tuple, Type, Union

from mtree import MtreeFile
from util import chdir, host_machine, run_cmd


class TaskMeta(ABCMeta):
    _registry: Dict[str, Type['Task']] = {}
    _reserved_names: Set[str] = {
        'bindings',
        'description',
        'inputs',
        'name',
        'outputs',
        'parameters',
        'run'
    }

    @classmethod
    def _validate_common(mcs, cls: Type['Task'], namespace) -> None:
        # No bindings should be defined initially, they are added once we
        # instantiate tasks and bind parameters.
        if len(getattr(cls, 'bindings', {})) > 0:
            raise ValueError(
                f"Task '{cls.name}' should not define any bindings"
            )

        # Any members must be a parameter type.
        parameters = getattr(cls, 'parameters')
        for name in namespace.keys():
            if name.startswith('_'):
                continue
            if name in mcs._reserved_names:
                continue
            if name not in parameters:
                raise ValueError(
                    f"Member '{name}' in task '{cls.name}' is not defined as a parameter"
                )

    @classmethod
    def _validate_named_task(mcs, cls: Type['Task'], name: str, namespace) -> None:
        mcs._validate_common(cls, namespace)

        parameters = getattr(cls, 'parameters')
        inputs = getattr(cls, 'inputs')
        outputs = getattr(cls, 'outputs')

        # Do some validation of the task definition.
        #
        # Ensure that the input parameter names are disjoint.
        overlap = inputs.keys() & parameters.keys()
        if len(overlap) > 0:
            raise ValueError(
                f"Task '{name}' has overlapping names: {', '.join(overlap)}"
            )
        # Make sure that none of the names overlap with reserved names.
        overlap = (inputs.keys() & mcs._reserved_names) | \
                  (outputs.keys() & mcs._reserved_names) | \
                  (parameters.keys() & mcs._reserved_names)
        if len(overlap) > 0:
            raise ValueError(
                f"Task '{name}' uses reserved names: {', '.join(overlap)}"
            )
        # Inputs must be a subclass of Task.
        for name, input_type in inputs.items():
            if not inspect.isclass(input_type) or not issubclass(input_type, Task):
                raise TypeError(
                    f"Input '{name}' in task '{cls.name}' must be a subclass of Task"
                )
        # Validate parameter types.
        for name, param in parameters.items():
            val = getattr(cls, name, None)
            if val is not None and type(val) is not param.type:
                raise TypeError(
                    f"Parameter '{name}' in task '{cls.name}' has type "
                    f"{type(getattr(cls, name))}, expected {param.typename}"
                )

    @classmethod
    def _validate_anonymous_task(mcs, cls: Type['Task'], namespace) -> None:
        mcs._validate_common(cls, namespace)

        invalid_keys = mcs._reserved_names & set(namespace.keys())
        if len(invalid_keys) > 0:
            raise ValueError(
                f"Anonymous task '{cls.__name__}' cannot define: {', '.join(invalid_keys)}"
            )

    def __new__(mcs, name, bases, namespace):
        cls = super().__new__(mcs, name, bases, namespace)
        if not inspect.isabstract(cls):
            task_name = namespace.get('name')
            if task_name is not None:
                mcs._validate_named_task(cls, task_name, namespace)
                mcs._registry[task_name] = cls
            else:
                mcs._validate_anonymous_task(cls, namespace)
        return cls

    @classmethod
    def lookup(mcs, name: str) -> Optional[Type['Task']]:
        return mcs._registry.get(name)

    @classmethod
    def task_names(mcs) -> List[str]:
        return list(mcs._registry.keys())


class TaskParameter:
    choices: Optional[List[Any]] = None
    default: Any
    description: str
    required: bool
    type: Any

    _initialized = False

    def __init__(self, **kwargs):
        self.description = kwargs['description']
        self.type = kwargs.get('type')
        self.default = kwargs.get('default', None)
        self.required = self.default is None
        self.choices = kwargs.get('choices', None)

        if self.default is not None:
            while callable(self.default):
                self.default = self.default()
            if not isinstance(self.default, self.type):
                raise TypeError(
                    f"Default value {type(self.default)} does not match parameter type {self.type}"
                )
        self._initialized = True

    # These objects are immutable after instantiation.
    def __setattr__(self, key, value):
        if self._initialized:
            raise AttributeError(f"Cannot modify attribute '{key}' of TaskParameter")
        super().__setattr__(key, value)

    @property
    def typename(self) -> str:
        if hasattr(self.type, '__name__'):
            return self.type.__name__
        return str(self.type)

    def str2val(self, s: str) -> Any:
        if self.type is bool:
            if s.lower() in ('1', 'true', 'yes', 'on'):
                val = True
            elif s.lower() in ('0', 'false', 'no', 'off'):
                val = False
            else:
                raise ValueError(f"Value '{s}' is not of type {self.typename}")
        else:
            try:
                val = self.type(s)
            except Exception as e:
                raise ValueError(f"Value '{s}' is not of type {self.typename}") from e
        return val


class TaskParameterBinding:
    value: Any
    source: 'TaskParameterBinding.BindingType'
    task: Optional[str]

    class BindingType(Enum):
        DEFAULT = 1,
        COMMAND_LINE = 2,
        OVERRIDDEN = 3,

    def __init__(self, value, source: BindingType, task=None):
        self.value = value
        self.source = source
        self.task = task

    def __str__(self) -> str:
        return str(self.value)


class Task(ABC, metaclass=TaskMeta):
    bindings: Dict[str, TaskParameterBinding] = {}
    _final_outputs: Optional[Dict[str, Any]] = None
    name: str
    description: str = ''
    inputs: Dict[str, Type['Task']] = {}
    outputs: Dict[str, Any] = {}
    parameters: Dict[str, TaskParameter] = {}

    def __init__(self):
        super().__init__()
        self._finished = False

        for name, param in self.parameters.items():
            self.bind({name: param.default},
                      TaskParameterBinding.BindingType.DEFAULT)
        for name, val in self.__class__.__dict__.items():
            if name in self.parameters:
                self.bind({name: val},
                          TaskParameterBinding.BindingType.OVERRIDDEN)

    def bind(self, params: Dict[str, Any], source: TaskParameterBinding.BindingType) -> None:
        for name, param in params.items():
            if name not in self.parameters:
                raise ValueError(
                    f"Task '{self.name}' has no parameter named '{name}'"
                )
            self.bindings[name] = TaskParameterBinding(value=param, source=source)

    def _run(self, ctx: SimpleNamespace) -> Dict[str, Any]:
        if self._final_outputs is not None:
            # Each task runs only once.
            return self._final_outputs

        for name, param in self.bindings.items():
            setattr(self, name, param.value)

        with chdir(Path.cwd() / self.name):
            outputs = self.run(ctx)
            if set(outputs.keys()) != set(self.outputs.keys()):
                missing = set(self.outputs.keys()) - set(outputs.keys())
                raise ValueError(
                    f"Task {self.name} did not produce expected outputs: {', '.join(missing)}"
                )
            for name, val in outputs.items():
                # It would be nice if we could validate this statically...
                expected_type = self.outputs[name]
                if not isinstance(val, expected_type):
                    raise TypeError(
                        f"Output '{name}' in task '{self.name}' has type "
                        f"{type(val)}, expected {expected_type}"
                    )
            self._final_outputs = outputs
            return outputs

    @abstractmethod
    def run(self, ctx) -> Dict[str, Any]: ...


class Config:
    command_line_parameters: List[str] = []
    config_file_object: Dict[str, Any] = {}
    CONFIG_FILE_VERSION = 1
    config_path: Path
    max_jobs: int = len(os.sched_getaffinity(0))
    task_params: Dict[str, Dict[str, Any]] = {}
    parser: argparse.ArgumentParser
    task: Type[Task]
    workdir: Path

    def __init__(self):
        self.workdir = Path(os.environ.get('BRICOLER_WORKDIR',
                                           Path.home() / 'bricoler'))
        self.config_path = Path(self.workdir / 'bricoler.json')

        parser = argparse.ArgumentParser(prog='bricoler')
        parser.add_argument(
            '-a', '--alias',
            action='store',
            help='define an alias for the current command-line invocation'
        )
        parser.add_argument(
            "-j", "--max-jobs",
            type=int,
            metavar='N',
            default=self.max_jobs,
            help='set the maximum number of concurrent jobs (default: number of CPUs)'
        )
        parser.add_argument(
            '-l', '--list',
            action='store_true',
            help=argparse.SUPPRESS  # only really meant for completion handlers
        )
        parser.add_argument(
            '-s', '--show',
            action='store_true',
            help='show all available tasks or task parameters'
        )
        parser.add_argument(
            '-w', '--workdir',
            metavar='DIR',
            default=self.workdir,
            help='set the work directory (default: $BRICOLER_WORKDIR or ${HOME}/bricoler)'
        )
        parser.add_argument(
            'task',
            nargs='?',
            help='the task to run'
        )
        self.parser = parser

    @property
    def aliases(self) -> List[Dict[str, Any]]:
        return self.config_file_object['aliases']

    def add_alias(self, name: str):
        # Remove an existing alias.  Perhaps we should rename it instead?
        self.config_file_object['aliases'] = [
            a for a in self.config_file_object['aliases'] if a['alias'] != name
        ]
        self.config_file_object['aliases'].append({
            "alias": name,
            "task": self.task.name,
            "parameters": self.command_line_parameters,
        })
        with self.config_path.open('w') as f:
            json.dump(self.config_file_object, fp=f, indent=4)

    def lookup_alias(self, name: str) -> Optional[Dict[str, Any]]:
        return next(
            (a for a in self.config_file_object['aliases'] if a['alias'] == name),
            None
        )

    def load(self) -> argparse.Namespace:
        # Parse global arguments and the task name.
        opts, args = self.parser.parse_known_args()

        self.workdir.mkdir(parents=True, exist_ok=True)

        # Load aliases from the configuration file.
        try:
            f = self.config_path.open('r')
        except FileNotFoundError:
            # Populate it with some initial structure.
            with self.config_path.open('w') as f:
                json.dump({
                    "aliases": [],
                    "version": Config.CONFIG_FILE_VERSION,
                }, fp=f, indent=4)
        finally:
            with self.config_path.open('r') as f:
                self.config_file_object = json.load(f)
                version = self.config_file_object.get('version', -1)
                if version != Config.CONFIG_FILE_VERSION:
                    raise ValueError(
                        f"Unknown or unsupported configuration file version: {version}"
                    )

        if opts.task:
            task = TaskMeta.lookup(opts.task)
            if task is None:
                alias = self.lookup_alias(opts.task)
                if alias is None:
                    raise ValueError(f"Unknown task '{opts.task}'")
                task = TaskMeta.lookup(alias['task'])
                if task is None:
                    raise ValueError(
                        f"Unknown task '{alias['task']}' in alias '{opts.task}'"
                    )
                args += [f"--{param}" for param in alias['parameters']]
            self.task = task

        # Parse task-specific arguments.  These are of the form
        # --<task>/<param>=<value>.
        for arg in args:
            if not arg.startswith('--'):
                raise ValueError(
                    f"Task parameters must start with '--': {arg}"
                )
            arg = arg[2:]
            if '=' not in arg:
                raise ValueError(
                    f"Task parameters must be of the form --<task>/<param>=<value>: {arg}"
                )
            key, val = arg.split('=', 1)
            if '/' not in key:
                raise ValueError(
                    f"Task parameters must be of the form --<task>/<param>=<value>: {arg}"
                )
            task_name, param_name = key.split('/', 1)
            if task_name != self.task.name:
                raise ValueError(
                    f"Task parameter '{param_name}' is not for task '{self.task.name}'"
                )
            param = self.task.parameters.get(param_name)
            if param is None:
                raise ValueError(
                    f"Task '{task_name}' has no parameter named '{param_name}'"
                )

            if task_name not in self.task_params:
                self.task_params[task_name] = {}
            self.task_params[task_name][param_name] = param.str2val(val)
            self.command_line_parameters.append(arg)

        return opts

    def usage(self) -> None:
        # XXX-MJ usage is not very good
        self.parser.print_usage()


class TaskSchedule:
    class TaskScheduleNode:
        task: Task
        children: Dict[str, 'TaskSchedule.TaskScheduleNode']

        def __init__(self, task: Type[Task]):
            self.task = task()
            self.children = {}
            for name, input in task.inputs.items():
                self.children[name] = TaskSchedule.TaskScheduleNode(input)

        def _run(self, ctx: SimpleNamespace) -> Dict[str, Any]:
            for input, child in self.children.items():
                outputs = child._run(ctx)
                inputs = {}
                for name, val in outputs.items():
                    inputs[name] = val
                setattr(self.task, input, SimpleNamespace(**inputs))
            return self.task._run(ctx)

        def __iter__(self):
            yield self
            for child in self.children.values():
                yield from child

    config: Config
    schedule: TaskScheduleNode

    def __init__(self, config: Config):
        self.config = config
        self.schedule = self.TaskScheduleNode(config.task)

        # Preen the schedule.
        tasks = {}
        for node in self.schedule:
            if node.task.name in tasks:
                node.task = tasks[node.task.name]
            else:
                tasks[node.task.name] = node.task

        # Bind command-line parameters.
        for node in self.schedule:
            if node.task.name in config.task_params:
                node.task.bind(
                    config.task_params[node.task.name],
                    TaskParameterBinding.BindingType.COMMAND_LINE
                )

    def run(self):
        ctx = SimpleNamespace(max_jobs=self.config.max_jobs)
        with chdir(self.config.workdir):
            self.schedule._run(ctx)

    @property
    def parameters(self) -> Dict[str, Tuple[TaskParameter, Any]]:
        """Return a mapping of parameter names to their values in the schedule."""
        result: Dict[str, Any] = {}

        def _collect(node: TaskSchedule.TaskScheduleNode):
            for name in node.task.parameters.keys():
                val = node.task.bindings.get(name, None)
                result[f"{node.task.name}/{name}"] = (node.task.parameters[name], val)

            for child in node.children.values():
                _collect(child)

        _collect(self.schedule)
        return result

    @property
    def tasks(self) -> Dict[str, Task]:
        """Return a mapping of task names to task instances in the schedule."""
        result: Dict[str, Task] = {}

        def _collect(node: TaskSchedule.TaskScheduleNode):
            result[node.task.name] = node.task
            for child in node.children.values():
                _collect(child)

        _collect(self.schedule)
        return result

    @property
    def target(self) -> Task:
        """Return the target task of the schedule."""
        return self.schedule.task


class GitRepository:
    def __init__(self, url: str, branch: Optional[str] = None):
        self.url = url
        self.branch = branch
        self.skip_clone = url.startswith('/')

    def git(self, args: List[str]):
        if not self.path:
            raise ValueError("Repository has not been cloned yet")
        return run_cmd(
            ['git', '-C', self.path] + args,
            capture_output=True
        )

    def clone(self, path: Path):
        self.path = path.resolve()
        if (path / ".git").is_dir():
            if self.skip_clone:
                return

            # Already cloned.  Make sure the correct branch is checked out.
            for name, url in self.remotes.items():
                if url == self.url:
                    remote = name
                    break
            else:
                raise ValueError(
                    f"Clone at '{path}' has no remote corresponding to '{self.url}'"
                )
            self.git(["fetch", remote])
            self.git(["checkout", f"{remote}/{self.branch}"])
        elif self.skip_clone:
            raise ValueError(
                f"Repository path '{self.url}' does not exist or is not a repo clone"
            )
        else:
            cmd = ["git", "clone", "--depth=1"]
            if self.branch:
                cmd += ["--branch", self.branch]
            cmd += [self.url, path.resolve()]
            run_cmd(cmd)

    @property
    def remotes(self) -> Dict[str, str]:
        result = {}
        output = self.git(["remote", "-v"])
        for line in output.stdout.decode().splitlines():
            parts = line.split()
            if len(parts) < 2:
                continue
            name = parts[0]
            url = parts[1]
            result[name] = url
        return result


class FreeBSDSrcRepository(GitRepository):
    def get___FreeBSD_version(self) -> int:
        file = self.path / 'sys' / 'sys' / 'param.h'
        with file.open('r') as f:
            pattern = re.compile(r'^\s*#define\s+__FreeBSD_version\s+(\d+)')
            for line in f:
                match = pattern.match(line)
                if match:
                    return int(match.group(1))
            raise ValueError(
                f"Could not obtain __FreeBSD_version from {file}"
            )

    def make(self, args: List[str], **kwargs):
        cmd = ['make', '-C', self.path.resolve()] + args
        return run_cmd(cmd, **kwargs)

    @functools.cache
    def machine_targets(self) -> List[str]:
        pattern = re.compile(r'^\s*\w+/\w+$')
        output = self.make(['targets'], capture_output=True).stdout.decode()
        targets = []
        for line in output.splitlines():
            if pattern.match(line.strip()):
                targets.append(line.strip())
        return targets


class GitCheckoutTask(Task):
    name = 'git-checkout'

    parameters = {
        'url': TaskParameter(
            description='URL of the Git repository to clone, or a filesystem path',
            type=str,
            required=True,
        ),
        'branch': TaskParameter(
            description='Branch to check out',
            type=str,
        ),
    }
    outputs = {
        'repo': GitRepository
    }

    def run(self, ctx, repotype=GitRepository):
        repo = repotype(self.url, self.branch)
        repo.clone(Path("./src"))
        return {'repo': repo}


class FreeBSDSrcGitCheckoutTask(GitCheckoutTask):
    name = 'freebsd-src-git-checkout'

    url = 'anongit@git.freebsd.org:src.git'
    branch = 'main'

    outputs = {
        'repo': FreeBSDSrcRepository,
        '__FreeBSD_version': int,
    }

    def run(self, ctx):
        outputs = super().run(ctx, repotype=FreeBSDSrcRepository)
        outputs['__FreeBSD_version'] = outputs['repo'].get___FreeBSD_version()
        return outputs


class FreeBSDSrcBuildTask(Task):
    name = 'freebsd-src-build'

    parameters = {
        'clean': TaskParameter(
            description='Clean build directories before building',
            type=bool,
            default=False,
        ),
        'kernel_config': TaskParameter(
            description='Kernel configuration to build',
            type=str,
            default='GENERIC',
        ),
        'machine': TaskParameter(
            description='Target machine architecture',
            type=str,
            default=host_machine(),
        ),
        'make_targets': TaskParameter(
            description='Make targets to build',
            type=str,  # XXX-MJ List[str]
            default=''
        ),
        'objdir': TaskParameter(
            description='Object directory path for the build',
            type=Path,  # XXX-MJ default must be computed after some partial eval
        ),
    }

    inputs = {
        'src': FreeBSDSrcGitCheckoutTask,
    }

    outputs = {
        'machine': str,
        'metalog': MtreeFile,
        'stagedir': Path,
    }

    def run(self, ctx):
        # See if the user specified a valid target platform.
        if '/' not in self.machine:
            machine = self.machine
            machine_arch = ''
        else:
            (machine, machine_arch) = self.machine.split('/', maxsplit=1)
        targets = self.src.repo.machine_targets()
        if machine_arch == '':
            matches = [target for target in targets if target.startswith(f"{machine}/")]
            if len(matches) == 1:
                machine_arch = matches[0].split('/', maxsplit=1)[1]
            else:
                raise ValueError(
                    f"Multiple architectures found for machine '{machine}': {' '.join(matches)}'"
                )
        if f"{machine}/{machine_arch}" not in targets:
            raise ValueError(
                f"Unknown target platform: {self.machine}"
            )

        objdir = self.objdir
        if objdir is None:
            objdir = Path(f"./obj.{machine}.{machine_arch}").resolve()
        objdir.mkdir(parents=True, exist_ok=True)

        stagedir = Path(f"./stage.{machine}.{machine_arch}").resolve()
        stagedir.mkdir(parents=True, exist_ok=True)

        mtree = MtreeFile()
        for target in self.make_targets.split():
            metalog = stagedir / f"METALOG.{target}.mtree"
            with open(metalog, 'w') as f:
                f.truncate(0)

            args = [
                target,
                "-ss",
                "-j", ctx.max_jobs,
                "-DNO_ROOT",
                f"DESTDIR={stagedir}",
                f"METALOG={metalog}",
                f"TARGET={machine}",
                f"KERNCONF={self.kernel_config}",
            ]
            if self.clean:
                args.append("WITH_CLEAN=")
            else:
                args.append("WITHOUT_CLEAN=")

            env = {
                "MAKEOBJDIRPREFIX": objdir,
                "SRCCONF": "/dev/null",
                "__MAKE_CONF": "/dev/null",
            }

            self.src.repo.make(args, env=env)

            mtree.load(metalog, append=True, contents_root=stagedir)

        return {
            'machine': f"{machine}/{machine_arch}",
            'metalog': mtree,
            'stagedir': stagedir,
        }


class FreeBSDSrcBuildAndInstallTask(FreeBSDSrcBuildTask):
    make_targets = "buildworld buildkernel installworld installkernel distribution"


class FreeBSDVMImageFilesystem(Enum):
    UFS = 'ufs'
    ZFS = 'zfs'


class FreeBSDVMImage(Task):
    name = 'freebsd-vm-image'

    inputs = {
        'src': FreeBSDSrcGitCheckoutTask,
        'build': FreeBSDSrcBuildAndInstallTask,
    }

    outputs = {
        'ssh_key_directory': Path
    }

    parameters = {
        'filesystem': TaskParameter(
            description='Filesystem type for the VM image',
            type=FreeBSDVMImageFilesystem,
            default=FreeBSDVMImageFilesystem.UFS,
        ),
        'hostname': TaskParameter(
            description='Hostname for the VM',
            type=str,
            default='freebsd',
        ),
        'image_size': TaskParameter(
            description='Size of the VM image',
            type=str,
            default='10g',
        ),
        'loader_tunables': TaskParameter(
            description='Loader tunables for the VM',
            type=str,  # XXX-MJ Dict[str, str]
            default='',
        ),
        'swap_size': TaskParameter(
            description='Size of the swap partition',
            type=str,
            default='2G',
        ),
    }

    def run(self, ctx) -> Dict[str, Any]:
        outputs = {}

        machine = self.build.machine
        mtree: MtreeFile = self.build.metalog
        stagedir = self.build.stagedir

        def add_config_file(path: Union[Path, str], *args, source: Optional[Path] = None):
            if type(path) is str:
                path = Path(path)
            if source is not None:
                shutil.copyfile(source, path)
                mode = "a"
            else:
                mode = "w"
            path.parent.mkdir(parents=True, exist_ok=True)
            with path.open(mode) as f:
                f.write("# Added by bricoler\n")
                contents = [textwrap.dedent(arg).strip() for arg in args if arg != ""]
                f.write(str.join("\n", contents) + "\n")
            mtree.add_file(path.resolve(), path)

        # Create ssh keys for the VM.
        with chdir(Path("ssh-keys")):
            keyfile = Path("id_ed25519_root").resolve()
            if not keyfile.is_file():
                run_cmd(["ssh-keygen", "-t", "ed25519", "-f", str(keyfile), "-N", ""])
            mtree.add_file(keyfile.with_suffix('.pub'),
                           Path("root/.ssh/authorized_keys"))
            outputs['ssh_key_directory'] = Path.cwd()

        add_config_file("etc/ssh/sshd_config",
                        "PermitRootLogin without-password",
                        source=(stagedir / "etc/ssh/sshd_config"))

        add_config_file("etc/rc.conf",
                        f"hostname={self.hostname}",
                        "ifconfig_vtnet0=SYNCDHCP",
                        "ifconfig_em0=SYNCDHCP",
                        "defaultroute_delay=2",
                        "sshd_enable=YES",
                        "sshd_rsa_enable=NO",
                        """
                        zfs_enable=YES
                        zpool_reguid=zroot
                        zpool_upgrade=zroot
                        """ if self.filesystem == FreeBSDVMImageFilesystem.ZFS else "")
        add_config_file("etc/fstab",
                        """
                        /dev/gpt/rootfs / ufs rw 1 1
                        """ if self.filesystem == FreeBSDVMImageFilesystem.UFS else "",
                        "none /dev/fd fdescfs rw 0 0")
        add_config_file("boot/loader.conf",
                        "autoboot_delay=1",
                        "console=comconsole",
                        "kern.geom.label.disk_ident.enable=0",
                        "zfs_load=YES" if self.filesystem == FreeBSDVMImageFilesystem.ZFS else "",
                        *[tunable for tunable in self.loader_tunables.split()])

        metalog_path = Path("METALOG.mtree").resolve()
        mtree.write(metalog_path)

        image_prefix = f"image.{self.build.machine.replace('/', '.')}"
        esp_image_path = Path(f"{image_prefix}-esp.fs").resolve()
        fs_image_path = Path(f"{image_prefix}.{self.filesystem.name}").resolve()
        vm_image_path = Path(f"{image_prefix}.img").resolve()

        makefs_cmd = ["makefs"]
        if self.filesystem == FreeBSDVMImageFilesystem.UFS:
            makefs_cmd += ["-t", "ffs", "-Z", "-o", "softupdates=1", "-o" "version=2"]
        else:
            makefs_cmd += ["-t", "zfs", "-o", "poolname=zroot", "-o", "bootfs=zroot"]
        makefs_cmd += [
            "-DD",
            "-s", self.image_size,
            fs_image_path,
            metalog_path,
        ]

        with chdir(stagedir):
            run_cmd(makefs_cmd)

        has_efi = not (machine.startswith('i386/') or machine.startswith('powerpc/'))
        if has_efi:
            efi_loaders = {
                'amd64': "bootx86.efi",
                'arm': "bootarm.efi",
                'arm64': "bootaa64.efi",
                'riscv': "bootriscv64.efi",
            }
            esp_dir = Path(image_prefix + "-efi")
            with chdir(esp_dir / "BOOT/EFI"):
                efi_loader = efi_loaders[machine.split('/')[0]]
                shutil.copyfile(stagedir / "boot/loader.efi", Path(efi_loader))

            makefs_cmd = [
                "makefs",
                "-t", "msdos",
                "-o", "fat_type=16",
                "-o", "sectors_per_cluster=1",
                "-o", "volume_label=EFI",
                "-s", "4m",
                esp_image_path,
                esp_dir,
            ]
            run_cmd(makefs_cmd)

        bootdir = stagedir / "boot"
        mkimg_cmd = [
            "mkimg",
            "-f", "raw",
            "-S", 512,
            "-o", vm_image_path,
        ]
        if machine.startswith('powerpc/'):
            mkimg_cmd += [
                "-s", "mbr",
                "-a", "1",
                "-p", f"prepboot:={bootdir / 'boot1.elf'}"
                "-p", f"freebsd:={vm_image_path}",
            ]
        else:
            mkimg_cmd += ["-s", "gpt"]
            if machine.startswith('amd64/') or machine.startswith('i386/'):
                mkimg_cmd += [
                    "-b", f"{bootdir / 'pmbr'}",
                    "-p", f"freebsd-boot/bootfs:={bootdir / 'gptboot'}",
                ]
            if has_efi:
                mkimg_cmd += [
                    "-p", f"efi:={esp_image_path}",
                ]
            mkimg_cmd += [
                "-p", f"freebsd-swap/swap::{self.swap_size}",
                "-p", f"freebsd-{self.filesystem.name}/rootfs:={fs_image_path}",
            ]

        run_cmd(mkimg_cmd)

        return outputs


def main() -> int:
    config = Config()
    try:
        args = config.load()
    except ValueError as e:
        print(f"usage error: {e}")
        return 1

    if not args.task:
        if args.show:
            print("Available tasks:")
            for task_name in TaskMeta.task_names():
                print(f"  {task_name}")
            for alias in config.aliases:
                print(f"  {alias['alias']} (alias for {alias['task']})")
            return 0
        elif args.list:
            for task_name in TaskMeta.task_names():
                print(task_name)
            for alias in config.aliases:
                print(alias['alias'])
            return 0
        else:
            config.usage()
            return 1

    sched = TaskSchedule(config)
    if args.alias:
        config.add_alias(args.alias)
        return 0
    elif args.show:
        print(f"{sched.target.name}:")
        if len(sched.target.description) > 0:
            print(sched.target.description)
        else:
            print("")
        width = max(len(name) for name in sched.parameters.keys()) + 2
        for name, param in sched.parameters.items():
            print(f"{name+':':<{width}} {param[0].description}")
            print(f"{'':{width+1}}{str(param[1])}")
        return 0
    elif args.list:
        sched = TaskSchedule(config)
        for task in sched.tasks.values():
            for name in task.parameters.keys():
                print(f"{task.name}/{name}")
        return 0
    else:
        sched = TaskSchedule(config)
        sched.run()
        return 0


if __name__ == '__main__':
    sys.exit(main())
